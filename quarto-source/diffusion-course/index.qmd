# Preface {.unnumbered}

Welcome to *Diffusion Models: Theory to Practice*.

This course aims to bridge the gap between rigorous mathematical theory (SDEs, ODEs) and practical implementation in PyTorch.

## Why this Course?

::: {.callout-note}
## The Core Philosophy
We believe that deep learning is not magic; it is **geometry** and **statistics** realized through computation.
:::

In this series, we will derive the fundamental objective function from the **Evidence Lower Bound (ELBO)**:

$$
\mathcal{L}_{\text{VLB}} = \mathbb{E}_{q(x_{1:T}|x_0)} \left[ \log \frac{q(x_T|x_0)}{p(x_T)} + \sum_{t=2}^T \log \frac{q(x_{t-1}|x_t, x_0)}{p_\theta(x_{t-1}|x_t)} - \log p_\theta(x_0|x_1) \right]
$$

We will treat every line of code as a mathematical statement.

## Prerequisites

-   Basic Probability Theory (Gaussian Distributions)
-   Stochastic Processes (Brownian Motion)
-   Python & PyTorch
